<!DOCTYPE html>
<html>
  <head>
    <script src="https://aframe.io/releases/1.0.4/aframe.min.js"></script>
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

<<<<<<< HEAD
    <style>
      .arjs-loader {
        height: 100%;
        width: 100%;
        position: absolute;
        top: 0;
        left: 0;
        background-color: rgba(0, 0, 0, 0.8);
        z-index: 9999;
        display: flex;
        justify-content: center;
        align-items: center;
=======
<script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

  window.onload = function() {
    AFRAME.registerComponent("videohandler", {
      init: function() {
        var marker = this.el;

        this.vid = document.querySelector("#vid");

        marker.addEventListener(
          "markerFound",
          function() {
            this.vid.play();
          }.bind(this)
        );

        marker.addEventListener(
          "markerLost",
          function() {
            this.vid.pause();
            this.vid.currentTime = 0;
          }.bind(this)
        );
>>>>>>> 3b687df8742818b3b0eba3a6fb21388124906d76
      }

      .arjs-loader div {
        text-align: center;
        font-size: 1.25em;
        color: white;
      }
    </style>
  </head>

<<<<<<< HEAD
  <body style="margin : 0px; overflow: hidden;">
    <!-- minimal loader shown until image descriptors are loaded. Loading may take a while according to the device computational power -->
    <div class="arjs-loader">
      <div>Loading, please wait...</div>
    </div>
=======
<body style="margin : 0px; overflow: hidden;">
  <div class="arjs-loader">
    <div>Loading, please wait...</div>
  </div>
  <a-scene
    vr-mode-ui="enabled: false;"
    renderer="antialias: true; alpha: true; precision: mediump;"
    embedded
    arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;"
  >
    <a-assets>
      <video
        src="https://raw.githack.com/afleet06/nando.github.io/master/fer.mp4"
        preload="auto"
        id="vid"
        response-type="arraybuffer"
        loop
        crossorigin
        webkit-playsinline
        autoplay
        muted
        playsinline
      ></video>
    </a-assets>
>>>>>>> 3b687df8742818b3b0eba3a6fb21388124906d76

    <!-- a-frame scene -->
    <a-scene
      vr-mode-ui="enabled: false;"
      renderer="logarithmicDepthBuffer: true;"
      embedded
      arjs="trackingMethod: best; sourceType: webcam;debugUIEnabled: false;"
    >
<<<<<<< HEAD
      <!-- a-nft is the anchor that defines an Image Tracking entity -->
      <!-- on 'url' use the path to the Image Descriptors created before. -->
      <!-- the path should end with the name without the extension e.g. if file is trex.fset' the path should end with trex -->
      <a-nft
        type="nft"
        url="<path-to-your-image-descriptors>"
        smooth="true"
        smoothcount="10"
        smootholerance=".01"
        smooththreshold="5"
      >
        <!-- as a child of the a-nft entity, you can define the content to show. here's a GLTF model entity -->
        <a-entity
          gltf-model="https://arjs-cors-proxy.herokuapp.com/https://raw.githack.com/AR-js-org/AR.js/master/aframe/examples/image-tracking/nft/trex/scene.gltf"
          scale="5 5 5"
          position="100 100 0"
        >
        </a-entity>
      </a-nft>
      <!-- static camera that moves according to the device movemenents -->
      <a-entity camera></a-entity>
    </a-scene>
  </body>
</html>
=======
      <a-video src="#vid" rotation="-90 0 0" position="50 150 -100" width="500" height="300">
      </a-video>
    </a-nft>
    <a-entity camera></a-entity>
  </a-scene>
</body>
>>>>>>> 3b687df8742818b3b0eba3a6fb21388124906d76
